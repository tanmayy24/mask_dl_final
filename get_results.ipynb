{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os \n",
    "from torchvision import transforms\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "from torchmetrics import JaccardIndex\n",
    "from lightning import seed_everything\n",
    "\n",
    "from maskpredformer.scheduled_sampling_trainer import MaskSimVPScheduledSamplingModule\n",
    "from maskpredformer.vis_utils import show_video_line\n",
    "\n",
    "seed_everything(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"checkpoints/simvp_ss_epoch=2-valid_last_frame_iou=0.456.ckpt\"\n",
    "module = MaskSimVPScheduledSamplingModule.load_from_checkpoint(ckpt_path, use_gt_data=True, unlabeled=False, load_datasets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WenmaSet(Dataset):\n",
    "    def __init__(self, data_path, data_type, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.data_type = data_type\n",
    "        self.transform = transform\n",
    "\n",
    "        if (\n",
    "            self.data_type == \"train\"\n",
    "            or self.data_type == \"val\"\n",
    "            or self.data_type == \"unlabeled\"\n",
    "        ):\n",
    "            self.num_frames = 22\n",
    "\n",
    "        else:\n",
    "            self.num_frames = 11\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        images = []\n",
    "        masks = []\n",
    "\n",
    "        if \"train\" in self.data_type:\n",
    "            ind = ind\n",
    "\n",
    "        elif \"val\" in self.data_type:\n",
    "            ind = ind + 1000\n",
    "\n",
    "        elif \"unlabeled\" in self.data_type:\n",
    "            ind = ind + 2000\n",
    "\n",
    "        elif \"hidden\" in self.data_type:\n",
    "            ind = ind + 15000\n",
    "\n",
    "        video_path = os.path.join(self.data_path, \"video_{}\".format(ind))\n",
    "\n",
    "        if \"hidden\" in self.data_type or \"unlabeled\" in self.data_type:\n",
    "            mask_path = None\n",
    "\n",
    "        else:\n",
    "            mask_path = os.path.join(video_path, \"mask.npy\")\n",
    "\n",
    "        for frame in range(self.num_frames):\n",
    "            image_path = os.path.join(video_path, \"image_{}.png\".format(frame))\n",
    "            image = np.array(Image.open(image_path))\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            images.append(image)\n",
    "            if mask_path != None:\n",
    "                if \"prediction\" in self.data_type:\n",
    "                    mask = np.load(mask_path)[frame + 11]\n",
    "                else:\n",
    "                    mask = np.load(mask_path)[frame]\n",
    "            else:\n",
    "                mask = torch.zeros((160, 240))\n",
    "            masks.append(mask)\n",
    "\n",
    "        return images, masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = torch.jit.load('checkpoints/unet9.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),           \n",
    "    transforms.Resize((160, 240)),          \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "           \n",
    "])\n",
    "data_path = \"data/Dataset_Student/\"\n",
    "data_type = \"val\"\n",
    "\n",
    "dataset= WenmaSet(data_path = data_path + data_type,\n",
    "                  data_type = data_type,\n",
    "                  transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_predictions_and_target(i):\n",
    "    imgs, masks = dataset[i]\n",
    "    mask_predictions = []\n",
    "    for i in range(len(imgs)):\n",
    "        image = imgs[i].unsqueeze(0).to(device)\n",
    "        mask_prediction = unet_model(image)\n",
    "        mask_predictions.append(mask_prediction.squeeze(0))\n",
    "    mask_predictions = [torch.argmax(pred, dim=0).detach().cpu() for pred in mask_predictions]\n",
    "    mask_predictions_input = mask_predictions[:11]\n",
    "    if data_type == \"hidden\":\n",
    "        targets = masks\n",
    "    else:\n",
    "        targets = masks[11:]\n",
    "    return torch.stack(mask_predictions_input), torch.from_numpy(np.stack(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = get_mask_predictions_and_target(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video_line(inputs, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video_line(targets, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_predictions(module, x):\n",
    "    x = x.unsqueeze(0).to(module.device)\n",
    "    cur_seq = module.sample_autoregressive(x, 11)\n",
    "    y_hat = cur_seq.squeeze(0).cpu().type(torch.uint8)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = get_predictions(module, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video_line(y_hat, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard IoU calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = JaccardIndex(task='multiclass', num_classes=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard(y_hat[-1], targets[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the Jaccard IoU for all data in validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_yhat = []\n",
    "all_targets = []\n",
    "for i in tqdm.tqdm(range(len(dataset))):\n",
    "    inputs, targets = get_mask_predictions_and_target(i)\n",
    "    y_hat = get_predictions(module, inputs)\n",
    "    all_yhat.append(y_hat[-1].cpu())\n",
    "    all_targets.append(targets[-1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.stack(all_yhat), \"val_preds.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_yhat = torch.load(\"val_preds.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard(all_yhat, torch.stack(all_targets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
